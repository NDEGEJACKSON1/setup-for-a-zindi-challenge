{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM/HFIX/jCRSi6oLvboz8eo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NDEGEJACKSON1/setup-for-a-zindi-challenge/blob/main/stressDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries (e.g. pandas, numpy, sklearn)."
      ],
      "metadata": {
        "id": "s5ZVCGiZWanN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data (e.g. a CSV file containing social media posts and labels indicating whether the post was written by a stressed individual)."
      ],
      "metadata": {
        "id": "NVAs6v56WOGG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhdR_RANVaqF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as skl\n",
        "import re\n",
        "\n",
        "from string import punctuation \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier #classifier\n",
        "from sklearn.metrics import accuracy_score #evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testData = pd.read_csv('test.csv')\n",
        "trainData = pd.read_csv('train.csv')\n",
        "sampleData = pd.read_csv('sample.csv')"
      ],
      "metadata": {
        "id": "Lp_9eO6wV6dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampleData.isna().sum()"
      ],
      "metadata": {
        "id": "NM5Dw33nmWgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(testData.head())"
      ],
      "metadata": {
        "id": "GKeSKtNTXsqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testData.isna().sum()"
      ],
      "metadata": {
        "id": "qXnOtl2hlxCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainData.head())"
      ],
      "metadata": {
        "id": "iyjRZjmlX32Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData.isna().sum()"
      ],
      "metadata": {
        "id": "zFyKxTfPl_9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the data. This may include cleaning the text (e.g. removing special characters, stemming words), and possibly creating new features (e.g. counting the number of exclamation points in a post)."
      ],
      "metadata": {
        "id": "n1xgseC6Woa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple function to clean text data \n",
        "\n",
        "def text_cleaning(text):\n",
        "    # Clean the text data\n",
        "\n",
        "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
        "    text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\s+', '', text) # remove numbers\n",
        "    text = text.lower()  # set in lowercase \n",
        "        \n",
        "    # Remove punctuation from text\n",
        "    text = ''.join([c for c in text if c not in punctuation])\n",
        "        \n",
        "    # Return a list of words\n",
        "    return(text)"
      ],
      "metadata": {
        "id": "a75-0hRnXTYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testData[\"text\"] = testData[\"text\"].apply(text_cleaning)\n",
        "trainData[\"text\"] = trainData[\"text\"].apply(text_cleaning)"
      ],
      "metadata": {
        "id": "65OJGJ6mYH9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into a training set and a testing set."
      ],
      "metadata": {
        "id": "DoLO_efAWoRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split features and target from train data \n",
        "X = trainData[\"text\"]\n",
        "y = trainData.label.values"
      ],
      "metadata": {
        "id": "womkKDqGXRQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform text data \n",
        "vectorizer = CountVectorizer(lowercase=False)\n",
        "\n",
        "vectorizer.fit(X)\n",
        "\n",
        "#transform train data \n",
        "X_transformed = vectorizer.transform(X)\n",
        "\n",
        "#transform test data\n",
        "test_transformed = vectorizer.transform(testData[\"text\"])"
      ],
      "metadata": {
        "id": "-GHJuNtYYSu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a machine learning model on the training data. This could be a classifier such as a support vector machine or a random forest."
      ],
      "metadata": {
        "id": "utqESE9sWoHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train and validate\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_transformed,\n",
        "    y,\n",
        "    test_size=0.10,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=y,\n",
        ")"
      ],
      "metadata": {
        "id": "dUCDmK0_XP0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a classifier\n",
        "stress_classifier = ExtraTreesClassifier() "
      ],
      "metadata": {
        "id": "5MVIy1SiawSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the stress_classifier \n",
        "stress_classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "pevEqimwrwnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test model performance on valid data \n",
        "y_preds = stress_classifier.predict(X_valid)\n",
        "\n",
        "# evalute model performance by using accuracy_score in the validation data\n",
        "accuracy_score(y_valid, y_preds) "
      ],
      "metadata": {
        "id": "5Wi1iLz7bZNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the tweets_classifier \n",
        "stress_classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "342LXQopbNAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the testing data. This might include calculating the precision, recall, and F1 score."
      ],
      "metadata": {
        "id": "BWhKmQXCXhtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create prediction from the test data\n",
        "test_preds = stress_classifier.predict(test_transformed)\n",
        "test_preds"
      ],
      "metadata": {
        "id": "JhTsFX4dXiuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_valid, y_preds)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_valid, y_preds)\n",
        "\n",
        "# Print the results\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n"
      ],
      "metadata": {
        "id": "5Y70zYzcppV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune the model by adjusting the hyperparameters (e.g. the learning rate, the regularization parameter)."
      ],
      "metadata": {
        "id": "_y0bK0rUWnvj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jsQ5jH0BXMG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the trained model to disk. \n",
        "for now a'm created submission file for competition"
      ],
      "metadata": {
        "id": "8eZRFEQWWm_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create submission file \n",
        "testData[\"label\"] = test_preds"
      ],
      "metadata": {
        "id": "Yj0fqAIuXJZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show sample submissoin rows\n",
        "testData.head() "
      ],
      "metadata": {
        "id": "HY7jOfLNcwu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save submission file\n",
        "testData = testData[['post_id','label']] \n",
        "testData.to_csv(\"first_submission.csv\", index=False) "
      ],
      "metadata": {
        "id": "uIJq2yz0c3XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the trained model and use it to make predictions on new, unseen data."
      ],
      "metadata": {
        "id": "1_OLgYSrWmTR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4HLqDRPXH0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}